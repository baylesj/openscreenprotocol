<pre class='metadata'>
Title: Open Screen Protocol
Shortname: openscreenprotocol
Level: 1
Status: w3c/ED
ED: https://webscreens.github.io/openscreenprotocol/
Canonical URL: ED
Editor: Mark Foltz, Google, https://github.com/mfoltzgoogle, w3cid 68454
Repository: webscreens/openscreenprotocol
Abstract: The Open Screen Protocol is a suite of network protocols that allow user agents to implement the [[PRESENTATION-API|Presentation API]] and the [[REMOTE-PLAYBACK|Remote Playback API]] in an interoperable fashion.
Group: Second Screen Community Group
Mailing List: public-webscreens@w3c.org
Mailing List Archives: https://lists.w3.org/Archives/Public/public-webscreens/
Markup Shorthands: markdown yes, dfn yes, idl yes
</pre>

<p boilerplate="copyright">
<a href="http://www.w3.org/Consortium/Legal/ipr-notice#Copyright">Copyright</a> Â© [YEAR] the Contributors to the [TITLE] Specification, published by the <a href="https://www.w3.org/community/webscreens/">Second Screen Community Group</a> under the <a href="https://www.w3.org/community/about/agreements/cla/">W3C Community Contributor License Agreement (CLA)</a>.
A human-readable <a href="http://www.w3.org/community/about/agreements/cla-deed/">summary</a> is available.
</p>

<!-- TODO: Add short names to Presentation API spec, so that BS autolinking works as designed. -->
<!-- TODO: Can autolinks to HTML51 be automatically generated? -->
<pre class="anchors">
urlPrefix: https://w3c.github.io/presentation-api/#dfn-; type: dfn; spec: PRESENTATION-API
    text: available presentation display
    text: controller
    text: controlling user agent
    text: controlling browsing context
    text: presentation
    text: presentation display
    text: presentation display availability
    text: presentation id
    text: presentation request url
    text: receiver
    text: receiving browsing context
    text: receiving user agent
    text: available presentation display
urlPrefix: https://w3c.github.io/presentation-api/; type: interface; spec: PRESENTATION-API
    text: PresentationConnection
urlPrefix: https://w3c.github.io/remote-playback/#dfn-; type: dfn; spec: REMOTE-PLAYBACK
    text: remote playback devices
    text: compatible remote playback device
    text: media resources
    text: availability sources set
    text: remote playback source
urlPrefix: https://www.w3.org/TR/html51/single-page.html; type: dfn; spec: HTML51
    text: media element
</pre>

<h2 class='no-num no-toc no-ref' id='status'>Status of this document</h2>

This specification was published by the [Second Screen Community
Group](https://www.w3.org/community/webscreens/). It is not a W3C Standard nor
is it on the W3C Standards Track. It should not be viewed as a stable
specification, and may change in substantial ways at any time. A future version
of this document will be published as a Community Group Report.

Please note that under the [W3C Community Contributor License Agreement
(CLA)](https://www.w3.org/community/about/agreements/cla/) there is a limited
opt-out and other conditions apply.

Learn more about [W3C Community and Business
Groups](http://www.w3.org/community/).

Introduction {#introduction}
============================

The Open Screen Protocol connects browsers to devices capable of rendering Web
content for a shared audience.  Typically, these are devices like
Internet-connected TVs, HDMI dongles, or "smart" speakers.

The protocol is a suite of subsidiary network protocols that enable two user
agents to implement the [[PRESENTATION-API|Presentation API]] and
[[REMOTE-PLAYBACK|Remote Playback API]] in an interoperable fashion.  This means
that a user can expect these APIs work as intended when connecting two devices
from independent implementations of the Open Screen Protocol.

The Open Screen Protocol is a specific implementation of these two APIs, meaning
that it does not handle all possible ways that browsers and presentation
displays could support these APIs.  The Open Screen Protocol specifically
supports browsers and displays that are connected via the same local area
network, and that initiate presentation or remote playback by sending a URL
from the browser to the target display.

The Open Screen Protocol is intended to be extensible, so that additional
capabilities can be added over time.  This may include new implementations of
existing APIs, or new APIs.

Terminology {#terminology}
--------------------------

We use the term "agent" to mean any implementation of this protocol
(browser, device, or otherwise), acting as a controller or a receiver.

We borrow terminology from the [[PRESENTATION-API|Presentation API]]. We call
the agent that is used to discover and initiate presentation of Web content on
another device the [=controller=] (or [=controlling user agent=] when it is a
browser).  We call the agent on the device rendering the Web content the
[=receiver=] or [=presentation display=] (or [=receiving user agent=] when it is
a browser). [=presentation display availability=] refers to whether or not a
[=receiver=] is compatible with a [=presentation request URL=]

We borrow terminology from the [[REMOTE-PLAYBACK|Remote Playback API]].  The
agent responsible for rendering media of a remote playback is called the
[=remote playback device=]. In this document, we also refer to it as the
*receiver* because it is shorter and keeps terminology consistent between
presentations and remote playbacks. Similarly, we use the term "controller"
(referred to as the "user agent" in the [[REMOTE-PLAYBACK|Remote Playback API]])
to refer to the agent that starts, terminates, and controls the remote playback.

For additional terms and idioms specific to the [[PRESENTATION-API|Presentation
API]] or [[REMOTE-PLAYBACK|Remote Playback API]], please consult the respective
specifications.


Requirements {#requirements}
============================

Presentation API Requirements {#requirements-presentation-api}
--------------------------------------------------------------

1.  A controlling user agent must be able to discover the presence of a
    presentation display connected to the same IPv4 or IPv6 subnet and reachable
    by IP multicast.

2.  A controlling user agent must be able to obtain the IPv4 or IPv6 address of
    the display, a friendly name for the display, and an IP port number for
    establishing a network transport to the display.

3.  A controlling user agent must be able to determine if the receiver is
    reasonably capable of rendering a specific [=presentation request URL=].

4.  A controlling user agent must be able to start a new presentation on a receiver given a
    [=presentation request URL=] and [=presentation ID=].

5.  A controlling user agent must be able to create a new
    {{PresentationConnection}} to an existing presentation on the
    receiver, given its [=presentation request URL=] and [=presentation ID=].

6.  It must be possible to to close a {{PresentationConnection}} between a
    controller and a presentation, and signal both parties with the
    reason why the connection was closed.

7.  Multiple controllers must be able to connect to a single presentation
    simultaneously, possibly from from one or more [=controlling user agents=].

8.  Messages sent by the controller must be delivered to the presentation (or
    vice versa) in a reliable and in-order fashion.

9.  If a message cannot be delivered, then the controlling user agent must be
    able to signal the receiver (or vice versa) that the connection should be
    closed with reason `error`.

10. The controller and presentation must be able to send and receive `DOMString`
    messages (represented as `string` type in ECMAScript).

11. The controller and presentation must be able to send and receive binary
    messages (represented as `Blob` objects in HTML5, or `ArrayBuffer` or
    `ArrayBufferView` types in ECMAScript).

12. The controlling user agent must be able to signal to the receiver to
    terminate a presentation, given its [=presentation request URL=] and [=presentation
    ID=].

13. The receiver must be able to signal all connected controlling user agents
    when a presentation is terminated.


Remote Playback API Requirements {#requirements-remote-playback}
----------------------------------------------------------------

Issue(3): Requirements for Remote Playback API

Non-Functional Requirements {#requirements-non-functional}
----------------------------------------------------------

1.  It should be possible to implement an Open Screen presentation display using
    modest hardware requirements, similar to what is found in a low end
    smartphone, smart TV or streaming device. See the [Device
    Specifications](device_specs.md) document for expected presentation display
    hardware specifications.

2.  It should be possible to implement an Open Screen controlling user agent on a
    low-end smartphone. See the [Device Specifications](device_specs.md) document
    for expected controlling user agent hardware specifications.

3.  The discovery and connection protocols should minimize power consumption,
    especially on the controlling user agent which is likely to be battery
    powered.

4.  The protocol should minimize the amount of information provided to a passive
    network observer about the identity of the user, activity on the controlling
    user agent and activity on the receiver.

5.  The protocol should prevent passive network eavesdroppers from learning
    presentation URLs, presentation IDs, or the content of presentation messages
    passed between controllers and presentations.

6.  The protocol should prevent active network attackers from impersonating a
    display and observing or altering data intended for the controller or
    presentation.

7.  The controlling user agent should be able to discover quickly when a
    presentation display becomes available or unavailable (i.e., when it connects
    or disconnects from the network).

8.  The controlling user agent should present sensible information to the user
    when a protocol operation fails.  For example, if a controlling user agent is
    unable to start a presentation, it should be possible to report in the
    controlling user agent interface if it was a network error, authentication
    error, or the presentation content failed to load.

9.  The controlling user agent should be able to remember authenticated
    presentation displays.  This means it is not required for the user to
    intervene and re-authenticate each time the controlling user agent connects
    to a pre-authenticated display.

10.  Message latency between the controller and a presentation should be minimized
    to permit interactive use.  For example, it should be comfortable to type in
    a form in the controller and have the text appear in the presentation in real
    time.  Real-time latency for gaming or mouse use is ideal, but not a
    requirement.

11. The controlling user agent initiating a presentation should communicate its
    preferred locale to the receiver, so it can render the presentation content
    in that locale.

12. It should be possible to extend the control protocol (above the discovery and
    transport levels) with optional features not defined explicitly by the
    specification, to facilitate experimentation and enhancement of the base
    APIs.


Discovery with mDNS {#discovery}
===============================

Agents may discover one another using [[RFC6763|DNS-SD]] over [[RFC6762|mDNS]].
To do so, agents must use the service name "_openscreen._udp.local".

Advertising Agents must use an instance name that is a prefix of the agent's
display name. If the instance name is not the complete display name (if it has
been truncated), it must be terminated by a null character.  It is prefix so
that the name displayed to the user pre-verification can be verified later.  It
is terminated by a null character in the case of truncation so that the
listening agent knows it has been truncated.  This complexity is necessary to
all for display names that exceed the size allowed in an instance name and for
such (possibly  truncated) display names to be visible to the user sooner
(before a QUIC connection is made).  Listening agents must treat instance names
as unverified and must verify that the instance name is a prefix of the verified
display name before showing the user a verified display name.

Advertising agents must include DNS TXT records with the following
keys and values:

: fp
:: The certificate fingerprint of the advertising agent.
    The format of the fingerprint is defined by [RFC 8122 section
    5](https://tools.ietf.org/html/rfc8122#section-5), excluding the
    "fingerprint:" prefix and including the hash function, space, and hex-encoded
    fingerprint.  The fingerprint value also functions as an ID for the agent.
    All agents must support the following hash functions: "sha-256", "sha-512".
    Agents must not support the following hash functions: "md2", "md5".

  <!-- TODO: include cross references to the specs for these hash functions. -->

: mv
:: An unsigned integer value that indicates that
    metadata has changed.   The advertising agent must update it to a greater
    value.  This signals to the listening agent that it should connect to the
    advertising agent to discover updated metadata.

  <!-- TODO: Add examples of sample mDNS records. -->


Future extensions to this QUIC-based protocol can use the same metadata
discovery process to indicate support for those extensions, through a
capabilities mechanism to be determined. If a future version of the Open Screen
Protocol uses mDNS but breaks compatibility with the metadata discovery process,
it should change the DNS-SD service name to a new value, indicating a new
mechanism for metadata discovery.


Transport and metadata discovery with QUIC {#transport}
=======================================================

If a listening agent ("controller") wants to connect to an advertising agent
("receiver"), or to learn further metadata about it, it initiates a [[QUIC]]
connection to the IP and port from the SRV record.  Prior to authentication,
a message may be exchanged (such as further metadata), but such info should be
treated as unverified (such as indicating to a user that a display name of an
unauthenticated agent is unverified).

To learn further metadata, the controller may send an agent-info-request
message (see [[#appendix-a]]) and receive back an agent-info-response message.
The messages may contain the following properties:

: display-name (required)
:: The display name of the receiver, intended to be displayed to a user by the
   controller. The controller should indicate through the UI if the receiver
   is not authenticated or if the display name changes.

: model-name (optional)
:: If the receiver is a hardware device, the model name of
    the device.  This is used mainly for debugging purposes, but may be
    displayed to the user of the requesting agent.

: audio-only (optional)
:: Generally speaking, receivers are assumed to support streaming both
audio and video. If an receiver wishes to indicate that they only support audio
stream, they can pass this property as true. In that case, the controller
should indicate through the UI that the receiver is audio only.

If the receiver is already authenticated, the controller has the ability to
request additional information by sending an streaming-capabilities-request
message, and receive back a streaming-capabilities-response message with the
following properties:

: supported-resolutions (required)
:: The receiver shall indicate what resolutions and refresh rates it supports
streaming content at.

<!-- TODO(jophba): figure out the units for this -->
: max-pixel-fill-rate (optional)
:: In combination with the supported resolutions, the receiver has the
option to to reply with the supported pixel fill rate in <UNITS>.
Requesting agents can use this information to make better-educated decisions
about what resolution and frame rates to stream content at.

<!-- TODO(jophba): do we need this info? -->
: supported-codecs (required)
:: The receiver must indicate to the controller what codecs it understands for
remote playback.

<!-- TODO(jophba): what other capabilities do we need here? -->
<!-- TODO: Add device type and/or capabilities -->

Listening agents act as QUIC clients.  Advertising agents act as QUIC servers.

If a listening agent wishes to receive messages from an advertising agent or an
advertising agent wishes to send messages to a listening agent, it may wish to
keep the QUIC connection alive.  Once neither side needs to keep the connection
alive for the purposes of sending or receiving messages, the connection should
be closed with an error code of 5139.  In order to keep a QUIC connection alive, an
agent may send an agent-status-request message, and any agent that receives an
agent-status-request message should send an agent-status-response message. Such
messages should be sent more frequently than the QUIC idle_timeout transport
parameter (see section 18 of [[QUIC]]) and QUIC PING
frames should not be used.  An idle_timeout transport parameter of 25 seconds is
recommended.  The agent should behave as though a timer less than the
idle_timeout were reset every time a message is sent on a QUIC stream.  If the
timer expires, a agent-status-request message should be sent.

If a client agent wishes to send messages to a server agent, the client
agent can connect to the server agent "on demand"; it does not need to
keep the connection alive.

The agent-info-response message and agent-status-response
messages may be extended to include additional information not defined
in this spec.  If done ad-hoc by applications and not in future specs,
keys should be chosen to avoid collision, such as by choosing large
integers or long strings.  Agents must ignore keys in the
agent-info-message that it does not understand to allow agents
to easily extend this message.

Messages delivery using CBOR and QUIC streams {#messages}
========================================================

Messages are serialized using [[RFC7049|CBOR]].  To
send a group of messages in order, that group of messages must be sent in one
QUIC stream.  Independent groups of messages (with no ordering dependency
across groups) should be sent in different QUIC streams.  In order to put
multiple CBOR-serialized messages into the the same QUIC stream, the following
is used.

For each message, the sender must write to the QUIC stream the following:

1.  A type key representing the type of the message, encoded as a variable-length
    integer (see [[#appendix-a]] for type keys)

2.  The message length encoded as a variable-length integer

3.  The message encoded as CBOR (whose length must match the value in step 2)

If an agent receives a message for which it does not recognize a
type key, it must close the QUIC connection with an application error
code of 404 and should include the unknown type key in the reason phrase
(see [[QUIC#section-19.4|QUIC transport section 19.4]]).

Variable-length integers are encoded in the same format as defined by
[[QUIC#section-16| QUIC transport section 16]].

Many messages are requests and responses, so a common format is defined for
those.  A request and a response includes a request ID which is an unsigned
integer chosen by the requester.  Responses must include the request ID of the
request they are associated with.

Authentication {#authentication}
================================

Issue(102): Incorporate material from the \[J-PAKE](j-pake.md) document.

Control Protocols {#control-protocols}
============================

Presentation Protocol {#presentation-protocol}
---------------------------------------------

This section defines the use of the Open Screen Protocol for starting,
terminating, and controlling presentations as defined by
[[PRESENTATION-API|Presentation API]]. [[#presentation-api]]
defines how APIs in [[PRESENTATION-API|Presentation API]] map to the
protocol messages defined in this section.

For all messages defined in this section, see [[#appendix-a]] for the full
CDDL definitions.

<!-- TODO: Add a capability that indicates support for the
presentation protocol.
See https://github.com/webscreens/openscreenprotocol/issues/123 -->

To learn which receivers are [=available presentation displays=] for a
particular URL or set of URLs, the controller may send a
presentation-url-availability-request message with the following values:

: urls
:: A list of presentation URLs.  Must not be empty.

: watch-duration
:: The period of time that the controller is interested in receiving updates
    about the URLs, should the availability change.

: watch-id
:: An identifier the receiver may use when sending updates about URL
    availability so that the controller knows which URLs the receiver is referring
    to.


In response, the receiver should send one presentation-url-availability-response
message with the following values:

: url-availabilities
:: A list of URL availability states (available,
    unavailable, or invalid).  Each state must correspond to the matching URL
    from the request by list index.


The receivers should later (up to the current time plus request
watch-duration) send presentation-url-availability-event messages if
URL availabilities change.  Such events contain the following values:

: watch-id
:: The watch-id given in the presentation-url-availability-response,
    used to refer to the presentation URLs whose availability has changed.

: url-availabilities
:: A list of URL availability states (available,
    unavailable, or invalid).  Each state must correspond to the URLs from the
    request referred to by the watch-id.

Note that these messages are not broadcasted to all controllers. They are sent
individually to controllers that have requested availability for the URLs that
have changed in availability state within the watch duration of the original
availability request.


To save power, the controller may disconnect the QUIC connection and
later reconnect to send availablity requests and receive availability
responses and updates.


To start a presentation, the controller may send a
presentation-start-request message to the receiver with the following
values:

: presentation-id
:: the presentation identifier

: url
:: the selected presentation URL

: headers
:: headers that the receiver should use to fetch the
    presentationUrl.  For example,
    [[PRESENTATION-API#establishing-a-presentation-connection|section 6.6.1]] of
    the Presentation API says that the Accept-Language header should be
    provided.

The presentation ID must follow the restrictions defined by
[[PRESENTATION-API#common-idioms|section 6.1]] of the Presentation API, in that
it must consist of at least 16 ASCII characters.


When the receiver receives the presentation-start-request, it should send back a
presentation-start-response message after either the presentation URL has been
fetched and loaded, or the receiver has failed to do so. If it has failed, it
must respond with the appropriate result (such as invalid-url or timeout).  If
it has succeeded, it must reply with a success result.  Additionally, the
response must include the following:

: connection-id
:: An ID that both agents can use to send connection messages
    to each other.  It is chosen by the receiver for ease of implementation: if
    the message receiver chooses the connection-id, it may keep the ID unique
    across connections, thus making message demuxing/routing easier.

<!-- TODO: Add optional HTTP response code to the response? -->

To send a presentation message, the controller or receiver may send a
presentation-connection-message with the following values:

: connection-id
:: The ID from the presentation-start-response or
    presentation-connection-open-response messages.

: message
:: the presentation message data.


To terminate a presentation, the controller may send a
presentation-termination-request message with the following values:

: presentation-id
:: The ID of the presentation to terminate.

: reason
:: The reason the presentation is being terminated.


When a [=receiver=] receives a presentation-termination-request, it should
send back a presentation-termination-response message to the requesting
controller.  It should also notify other controllers about the termination by sending
a presentation-termination-event message.  And it can send the same message if
it terminates a presentation without a request from a controller to do so. This
message contains the following values:

: presentation-id
:: The ID of the presentation that was terminated.

: reason
:: The reason the presentation was terminated.

<!-- TODO: Split up reason into reason and whether it was triggered by the user
or not? -->


To accept incoming connections requests from controller, a receiver
must receive and process the presentation-connection-open-request
message which contains the following values:

: presentation-id
:: The ID of the presentation to connect to.

: url
:: The URL of the presentation to connect to.


The receiver should, upon receipt of a
presentation-connection-open-request message, send back a
presentation-connection-open-response message which contains the
following values:

: result
:: a code indicating success or failure, and the reason for the failure

: connection-id
:: An ID that both agents can use to send connection messages
    to each other.  It is chosen by the receiver for ease of implementation (if
    the message receiver chooses the connection-id, it may keep the ID unique
    across connections, thus making message demuxing/routing easier).


A controller may terminate a connection without terminating the presentation by
sending a presentation-connection-close-request message with the following
values:

: connection-id
:: The ID of the connection to close.


The receiver should, upon receipt of a presentation-connection-close-request,
send back a presentation-connection-close-response message with the following
values:

: result
:: If the close succeed or failed, and if it failed why it failed.

The receiver may also close a connection without a request from the controller
to do so and without terminating a presentation.  If it does so, it should send
a presentation-connection-close-event to the controller with the following
values:

: connection-id
:: The ID of the connection that was closed

: reason
:: The reason the connection was closed

: error-message
:: A debug message suitable for a log or perhaps presented to
    the user with more explanation as to why it was closed.

<!-- TODO: Why does the Presentation API spec not mention the use of the close
message? -->

<!-- TODO: Specify message ordering groups. -->


Presentation API {#presentation-api}
---------------------------------------------

This section defines how the [[PRESENTATION-API|Presentation API]] uses the
[[#presentation-protocol]].

When [[PRESENTATION-API#the-list-of-available-presentation-displays|section
6.4.2]] says "This list of presentation displays ... is populated based on an
implementation specific discovery mechanism", the [=controlling user agent=] may
use the mDNS, QUIC, agent-info-request, and
presentation-url-availability-request messages defined previously in this spec
to discover receivers.

When [[PRESENTATION-API#the-list-of-available-presentation-displays|section
6.4.2]] says "To further save power, ... implementation specific discovery of
presentation displays can be resumed or suspended.", the [=controlling user
agent=] may use the power saving mechanism defined in the previous section.

When [[PRESENTATION-API#starting-a-presentation-connection|section 6.3.4]] says
"Using an implementation specific mechanism, tell U to create a receiving
browsing context with D, presentationUrl, and I as parameters.", U (the
[=controlling user agent=]) may send a presentation-start-request message to D
(the receiver), with I for the presentation identifier and presentationUrl for
the selected presentation URL.

<!-- TODO: Once the Presentation API has text about reconnecting via an
implementation specific mechanism, quote that here and map it to a message -->

When [[PRESENTATION-API#sending-a-message-through-presentationconnection|section
6.5.2]] says "Using an implementation specific mechanism, transmit the contents
of messageOrData as the presentation message data and messageType as the
presentation message type to the destination browsing context", the
[=controlling user agent=] may send a presentation-connection-message with
messageOrData for the presentation message data.  Note that the messageType is
embedded in the encoded CBOR type and does not need an additional value in the
message.

When
[[PRESENTATION-API#terminating-a-presentation-in-a-controlling-browsing-context|section
6.5.6]] says "Send a termination request for the presentation to its receiving
user agent using an implementation specific mechanism", the [=controlling user
agent=] may send a presentation-termination-request message.

When [[PRESENTATION-API#monitoring-incoming-presentation-connections|section
6.7.1]]
says "it MUST listen to and accept incoming connection requests from a
controlling browsing context using an implementation specific
mechanism", the [=receiving user agent=] must receive and process the
presentation-connection-open-request.

When [[PRESENTATION-API#monitoring-incoming-presentation-connections|section
6.7.1]] says "Establish the connection between the controlling and receiving
browsing contexts using an implementation specific mechanism.", the [=receiving
user agent=], must send a presentation-connection-open-response message.


Remote Playback Protocol {#remote-playback-protocol}
----------------------------------------------------

This section defines the use of the Open Screen Protocol for starting, terminating,
and controlling remote playback of media as defined by the
[[REMOTE-PLAYBACK|Remote Playback API]].  [[#remote-playback-api]] defines how
APIs in [[REMOTE-PLAYBACK|Remote Playback API]] map to the protocol messages
defined in this section.

For all messages defined in this section, see Appendix A for the full
CDDL definitions.

<!-- TODO: Add a capability that indicates support for the
remote playback protocol.
See https://github.com/webscreens/openscreenprotocol/issues/123 -->
<!-- TODO: Frequency to update current-time (HtmlMediaElement does every 250ms?) -->
<!-- TODO: extended mime types in source tag? -->
<!-- TODO: media queries replacing URLs? -->

To learn which receivers are [=compatible remote playback device=]s (also called
available [=remote playback devices=]) for a particular URL or set of URLs, the
controller may send a remote-playback-availability-request message with the
following values:

: urls
:: A list of [=media resources=].  Must not be empty.

: headers
:: headers that the receiver should use to fetch the
    urls.  For example,
    [[REMOTE-PLAYBACK#establishing-a-connection-with-a-remote-playback-device|section 6.2.4 of
    the Remote Playback API]] says that the Accept-Language header should be
    provided.

: watch-duration
:: The period of time that the controller is interested in receiving updates
    about the URLs, should the availability change.

: watch-id
:: An identifier the receiver may use when sending updates about URL
    availability so that the controller knows which URLs the receiver is referring
    to.

In response, the receiver should send a remote-playback-availability-response
message with the following values:

: url-availabilities
:: A list of URL availability states (available,
    unavailable, or invalid).  Each state must correspond to the matching URL
    from the request by list index.


The receivers should later (up to the current time plus request
watch-duration) send remote-playback-availability-event  messages if
URL availabilities change.  Such events contain the following values:

: watch-id
:: The watch-id given in the presentation-url-availability-response,
    used to refer to the presentation URLs whose availability has changed.

: url-availabilities
:: A list of URL availability states (available,
    unavailable, or invalid).  Each state must correspond to the URLs from the
    request referred to by the watch-id.

Note that these messages are not broadcasted to all controllers. They are sent
individually to controllers that have requested availability for the URLs that
have changed in availability state within the watch duration of the original
availability request.

To save power, the controller may disconnect the QUIC connection and
later reconnect to send availablity requests and receive availability
responses and updates.


To start remote playback, the controller may send a
remote-playback-start-request message to the receiver with the following
values:

: remote-playback-id
:: An identifier that uniquely identifies the remote playback from the
    controller to the receiver.  It does not need to be unique across all remote
    playbacks from all controllers to that receive nor unique across all remote
    playbacks from that  controller to all receivers.

: urls
:: The [=media resources=] that the controller has selected for playback on the
    receiver.

: text-track-urls
:: URLs of text tracks associated with the [=media resources=].

: controls
:: Initial controls for modifying the initial state of the remote playback, as
    defined in [[#remote-playback-state-and-controls]].  The controller may send
    controls that are optional for the receiver to support before it knows the
    receiver supports them.  If the receiver does not support them, it will
    ignore them and the controller will learn that it does not support them from
    the remote-playback-start-response message.


When the receiver receives a remote-playback-start-request message, it should
send back a remote-playback-start-response message.  It should do so quickly,
usually before the [=media resource=] has been loaded and instead give updates
of the progress of  loading with remote-playback-state-event messages, unless
the receiver decides to not attempt to load the resource at all.  If it chooses
not to, it must respond with the appropriate failure result (such as timeout or
invalid-url).  Additionally, the response must include the following:

: state
:: The initial state of the remote playback, as defined in
    [[#remote-playback-state-and-controls]].


If the controller wishes to modify the state of the remote playback (for
example, to pause, resume, skip, etc), it may send a
remote-playback-modify-request message with the following values:

: remote-playback-id
:: The ID of the remote playback to be modified.

: controls
:: Updated controls as defined in {#remote-playback-state-and-controls}

When a receiver receives a remote-playback-modify-request it should send a
remote-playback-modify-response message in reply with the following values:

: state
:: The updated state of the remote playback as defined in
    [[#remote-playback-state-and-controls]].

When the state of remote playback changes without request for modification from
the controller (such as when the skips or pauses due to user user interaction on
the receiver), the receiver may send a remote-playback-state-event to the
controller.

: remote-playback-id
:: The ID of the remote playback whose state has changed.

: state
:: The updated state of the remote playback, as defined in
    [[#remote-playback-state-and-controls]].


To terminate the remote playback, the controller may send a
remote-playback-termination-request message with the following values:

: remote-playback-id
:: The ID of the remote playback to terminate.

: reason
:: The reason the remote playback is being terminated.

When a receiver receives a presentation-termination-request, it should
send back a presentation-termination-response message to the controller.

If a receiver terminates a remote playback without a request from the controller
to do so, it must send a remote-playback-termination-event message to the
controller with the following values:

: remote-playback-id
:: The ID of the remote playback that was terminated.

: reason
:: The reason the remote playback was terminated.

As mentioned in
[[REMOTE-PLAYBACK#disconnecting-from-a-remote-playback-device|Remote Playback
API section 6.2.7]], terminating the remote playback means the controller is no
longer controlling the remote playback and does not necessarily stop media from
rendering on the receiver.  Whether or not the receiver stops rendering media depends
upon the implmentation of the receiver.



Remote Playback State and Controls {#remote-playback-state-and-controls}
------------------------------------------------------------------------

In order for the controller and receiver to stay in sync with regards to the
state of the remote playback, the controller may send controls to modify the state
(for example, via the remote-playback-modify-request message) and the receiver
may send updates about state changes (for example, via the
remote-playback-state-event message).

The controls sent by the controller include the follwing individual control
values, each of which is optional.  This allows the controller to change one
control value or many control values at once without having to specify all
control values every time.  A non-present control value indicates no change.  A
present control value indicates the change defined below. These controls
intentionally mirror settable attributes and methods of the
[HtmlMediaElement](https://html.spec.whatwg.org/multipage/media.html#htmlmediaelement).

: source
:: Change the [=media resource=] URL. See
    [HtmlMediaElement.src](https://html.spec.whatwg.org/multipage/media.html#dom-media-src)
    for more details. Must not be used in the initial controls of the
    remote-playback-start-request message (which already contains a list of URLs).

: preload
:: Set how aggresively to preload media. See
    [HtmlMediaElement.preload](https://html.spec.whatwg.org/multipage/media.html#dom-media-preload)
    for more details. Should only be used in the initial controls of the
    remote-playback-start-request message or when the source is changed.  If not
    set in the initial controls, it is left to the receiver to decide.  This is
    optional for the receiver to support and if not supported, the receiver will
    behave as though it were never set.

: loop
:: Set whether or not to loop media. See
    [HtmlMediaElement.loop](https://html.spec.whatwg.org/multipage/media.html#dom-media-loop)
    for more details. Should only be used in the initial control of the
    remote-playback-start-request.  If not set in the initial controls, it is
    assumed to be false.

: paused
:: If true, pause; if false, resume.  See
    [HtmlMediaElement.pause()](https://html.spec.whatwg.org/multipage/media.html#dom-media-pause).
    and
    [HtmlMediaElement.play()](https://html.spec.whatwg.org/multipage/media.html#dom-media-play)
    for more details.  If not set in the initial controls, it is left to the
    receiver to decide.

: muted
:: If true, mute; if false, unmute.  See
    [HtmlMediaElement.muted](https://html.spec.whatwg.org/multipage/media.html#dom-media-muted)
    for more details.  If not set in the initial controls, it is left to the
    receiver to decide.

: volume
:: Set the audio volume in the range from 0.0 to 1.0 inclusive.  See
    [HtmlMediaElement.volume](https://html.spec.whatwg.org/multipage/media.html#dom-media-volume)
    for more details.  If not set in the initial controls, it is left to the
    receiver to decide.

: seek
:: Seek to a precise time.  See
    [HtmlMediaElement.currentTime](https://html.spec.whatwg.org/multipage/media.html#dom-media-currenttime)
    for more details.

: fast-seek
:: Seek to an approximate time as fast as possible. See
    [HtmlMediaElement.fastSeek()](https://html.spec.whatwg.org/multipage/media.html#dom-media-fastseek)
    for more details.

: playback-rate
:: Set the rate a which the media plays.  See
    [HtmlMediaElement.playbackRate](https://html.spec.whatwg.org/multipage/media.html#dom-media-playbackrate)
    for more details.  If not set in the initial controls, it is left to the
    receiver to decide.  This is optional for the receiver to support and if not
    supported, the receiver will behave as though it were never set.

: poster
:: Set the URL of an image to show when video data is not available.  See
    [HtmlMediaElement.poster](https://html.spec.whatwg.org/multipage/media.html#dom-media-poster)
    for more details. If not set in the initial controls, no poster is used and
    the receiver can choose what to render when video data is unavailable.  This
    is optional for the receiver to support and if not supported, the receiver
    will behave as though it were never set.

: enabled-audio-track-ids
:: Enable included audio tracks by ID and disable all other audio tracks. See
    [HtmlMediaElement.audioTracks](https://html.spec.whatwg.org/multipage/media.html#dom-media-audiotracks)
    for more details.

: select-video-track-id
:: Select the given video track by ID and unselect all other video tracks.  See
    [HtmlMediaElement.videoTracks](https://html.spec.whatwg.org/multipage/media.html#dom-media-videotracks)
    for more details.

: added-text-tracks
:: Add text tracks with the given kinds, labels, and languages. See
    [HtmlMediaElement.addTextTrack](https://html.spec.whatwg.org/multipage/media.html#dom-media-addtexttrack)
    for more details.  This is optional for the receiver to support and if not
    supported, the receiver will behave as though it were never set.

: changed-text-tracks
:: Change text tracks by ID.  All other text tracks are left
    unchanged.  Set the mode, add cues, and remove cues by id.  See
    [HtmlMediaElement.textTracks](https://html.spec.whatwg.org/multipage/media.html#dom-media-texttracks)
    for more details.  Note that future specifications or extensions to this
    specifications are expected to add values to the added text-track-cue
    values (such as text size, alighment, position, etc).  Adding and removing
    cues is optional for the receiver to support and if not supported, the
    receiver will behave as though no cues were added or removed (both adding
    and removing are indicated via the support for "added-cues").



The states sent by the receiver include the following individual state values,
each of which is optional.  This allows the receiver to update the controller
about one state value or many state values at once without having to specify all
state values every time.  A non-present state value indicates the state has not
changed.

: supports
:: The controls the receiver supports.  These may differ for different [=media
    resource=]s and should not changes unless the [=media resource=] changes.  If
    not present in the intial state in the remote-playback-start-response
    message, support for nothing is assumed.

: source
:: The current [=media resource=] URL. See
    [HtmlMediaElement.currentSrc](https://html.spec.whatwg.org/multipage/media.html#dom-media-currentsrc).
    Must be present in the intial state in the remote-playback-start-response
    message.

: loading
:: The state of network activity for loading the [=media resource=].  See
    [HtmlMediaElement.networkState](https://html.spec.whatwg.org/multipage/media.html#dom-media-networkstate).
    If not present in the intial state in the remote-playback-start-response
    message, it is assumed to be empty.

: loaded
:: The state of the loaded media (whether enough is loaded to play).  See
    [HtmlMediaElement.readyState](https://html.spec.whatwg.org/multipage/media.html#dom-media-readystate).
    If not present in the intial state in the remote-playback-start-response
    message, it is assumed to be nothing.

: error
:: A major error occurred which prevents the remote playback from continuing. See
    [HtmlMediaElement.error](https://html.spec.whatwg.org/multipage/media.html#dom-media-error) and
    [HtmlMediaElement media error codes](https://html.spec.whatwg.org/multipage/media.html#concept-mediaerror-code).
    If not present in the intial state in the remote-playback-start-response
    message, it is assumed there is no such major error.

: epoch
:: The "zero time" of the media timeline.  See
    [HtmlMediaElement's timeline offset](https://html.spec.whatwg.org/multipage/media.html#timeline-offset) and
    [HtmlMediaElement.getStartDate()](https://html.spec.whatwg.org/multipage/media.html#dom-media-getstartdate).
    If not present in the intial state in the remote-playback-start-response
    message, it is assumed to be unknown.

: duration
:: The duration of the media timeline.  See
    [HtmlMediaElement.duration](https://html.spec.whatwg.org/multipage/media.html#dom-media-duration).
    If not present in the intial state in the remote-playback-start-response
    message, it is assumed to be unknown.  For unbounded streams, it may be "forever".

: buffered-time-ranges
:: The time ranges for which media has been buffered.  See
    [HtmlMediaElement.buffered](https://html.spec.whatwg.org/multipage/media.html#dom-media-buffered).

: played-time-ranges
:: The time ranges for which media has been played.   See
    [HtmlMediaElement.played](https://html.spec.whatwg.org/multipage/media.html#dom-media-played).

: seekable-time-ranges
:: The time ranges for which media is seekable (ranges the controller or the
    user on the receiver may seek to).   See
    [HtmlMediaElement.seekable](https://html.spec.whatwg.org/multipage/media.html#dom-media-seekable).

: position
:: The playback position.  See
    [HtmlMediaElement's official playback
    position](https://html.spec.whatwg.org/multipage/media.html#official-playback-position)
    and
    [HtmlMediaElement.currentTime](https://html.spec.whatwg.org/multipage/media.html#dom-media-currenttime).
    If not present in the intial state in the remote-playback-start-response
    message, it is assumed to be 0.

: playbackRate
:: The current rate of playback on a scale where 1.0 is "normal speed".  See
    [HtmlMediaElement.playbackRate](https://html.spec.whatwg.org/multipage/media.html#dom-media-playbackrate).
    If not present in the intial state in the remote-playback-start-response
    message, it is assumed to be 1.0.

: paused
:: Whether media is paused or not.  See
    [HtmlMediaElement.paused](https://html.spec.whatwg.org/multipage/media.html#dom-media-paused).
    If not present in the intial state in the remote-playback-start-response
    message, it is assumed to be false.

: seeking
:: Whether the receiver is seeking or not.  See
    [HtmlMediaElement.seeking](https://html.spec.whatwg.org/multipage/media.html#dom-media-seeking).
    If not present in the intial state in the remote-playback-start-response
    message, it is assumed to be false.

: stalled
:: If true, media is not playing because not enough media is loaded, and false otherwise.  See
    [HtmlMediaElement.stalled](https://html.spec.whatwg.org/multipage/media.html#event-media-stalled).
    If not present in the intial state in the remote-playback-start-response
    message, it is assumed to be false.

: ended
:: Whether media has reached the end or not.  See
    [HtmlMediaElement.ended](https://html.spec.whatwg.org/multipage/media.html#dom-media-ended).
    If not present in the intial state in the remote-playback-start-response
    message, it is assumed to be false.

: volume
:: The current volume of playback on a scale of 0.0 to 1.0.  See
    [HtmlMediaElement.volume](https://html.spec.whatwg.org/multipage/media.html#dom-media-volume).

: muted
:: True if audio is muted (overriding the volume value) and false otherwise.
    See
    [HtmlMediaElement.muted](https://html.spec.whatwg.org/multipage/media.html#dom-media-muted).

: resolution
:: The "intrinsic width" and "intrinsic width" of the video.  See
    [HtmlMediaElement.videoWidth](https://html.spec.whatwg.org/multipage/media.html#dom-media-videowidth)
    and
    [HtmlMediaElement.videoHeight](https://html.spec.whatwg.org/multipage/media.html#dom-media-videoheight).

: audio-tracks
:: The audio tracks available, which can individually enabled or disabled.  See
    [HtmlMediaElement.audioTracks](https://html.spec.whatwg.org/multipage/media.html#dom-media-audiotracks)

: video-tracks
:: The video tracks available, one of which can be selected.  See
    [HtmlMediaElement.videoTracks](https://html.spec.whatwg.org/multipage/media.html#dom-media-videotracks)

: text-tracks
:: The text tracks available, which can be individually shown, hidden, or disabled.  See
    [HtmlMediaElement.videoTracks](https://html.spec.whatwg.org/multipage/media.html#dom-media-videotracks).
    The controller can also add cues to and remove cues from text tracks.



All times, time ranges, and durations (such as positon, duration, and
seekable-time-ranges) used above use a common media-time value (see Appendix A)
which includes a time scale.  This allows time values which work on different
time scales to be expressed without loss of precision.  The scale is represented
in hertz, such as 90000 for 90000hz, a common time scale for video.


Remote Playback API {#remote-playback-api}
------------------------------------------

This section defines how the [[REMOTE-PLAYBACK|Remote Playback API]] uses the
messages defined in [[#remote-playback-protocol]].

When [[REMOTE-PLAYBACK#the-list-of-available-remote-playback-devices|section
6.2.1.2]] says "This list contains remote playback devices and is populated
based on an implementation specific discovery mechanism" and
[[REMOTE-PLAYBACK#the-list-of-available-remote-playback-devices|section
6.2.1.4]] says "Retrieve available remote playback devices (using an
implementation specific mechanism)", the user agent may use the
mDNS, QUIC, agent-info-request, and remote-playback-availability messages
defined previously in this spec to discover [=remote playback devices=].  The
remote-playback-availiability urls must contain the [=availability sources set=].

When
[[REMOTE-PLAYBACK#establishing-a-connection-with-a-remote-playback-device|section
6.2.4]] says "Request connection of remote to device. The implementation of this
step is specific to the user agent." and  "Synchronize the current media element
state with the remote playback state", the user agent may send the
remote-playback-start-request message to start remote playback.  The
remote-playback-start-request urls must contain the [=remote playback source=].
The current [[REMOTE-PLAYBACK|Remote Playback API]] only allows a single source,
but the protocol allows for several and future versions of
[[REMOTE-PLAYBACK|Remote Playback API]] may allow for several.

When
[[REMOTE-PLAYBACK#establishing-a-connection-with-a-remote-playback-device|section
6.2.4]] says "The mechanism that is used to connect the user agent with the
remote playback device and play the remote playback source is an implementation
choice of the user agent. The connection will likely have to provide a two-way
messaging abstraction capable of carrying media commands to the remote playback
device and receiving media playback state in order to keep the media element
state and remote playback state in sync", the user agent may send
remote-playback-modify-request messages to change the remote playback state
based on changes to the local media element and receive
remote-playback-modify-response and remote-playback-state-event messages to
change the local media element based on changes to the remote playback state.

<!-- TODO: Have a very descriptive, precise algorithm for what messages to send
when the local media element changes and what changes to make to the remote
media element when controls are received? -->

When
[[REMOTE-PLAYBACK#establishing-a-connection-with-a-remote-playback-device|section
6.2.7]] says "Request disconnection of remote from the device. The
implementation of this step is specific to the user agent.", the controlling
user agent may send the remote-playback-termination-request message.


Security and Privacy {#security}
================================

Issue(13): Describe security architecture.

Data to be secured {#security-data}
-----------------------------------

Threat model {#security-threat}
-------------------------------

Mitigations and defenses {#security-defenses}
---------------------------------------------

Appendix A: Messages {#appendix-a}
====================

The following messages are defined with [[CDDL]]. When
integer keys are used, a comment is appended to the line to indicate
the name of the field. Each root message (one that can be put into a
QUIC stream without being enclosed by another message) has a comment
indicating the message type key.

Smaller numbers should be reserved for message that will be sent more
frequently or are very small or both and larger numbers should be
reserved for messages that are infrequently sent or large or both
because smaller type keys encode on the wire smaller.

<!-- TODO: Make a bikeshed formatter CDDL -->
<!-- TODO(jophba): Can we have this CDDL in a separate file, and have bikeshed
     import it? I'm not a huge fan of this approach...
-->

<pre>
; type key 10
agent-info-request = {
  request
}

; type key 11
agent-info-response = {
  response
  1: agent-info ; agent-info
}

streaming-capabilities-request = {
  request
}

streaming-capabilities-response = {
  response
  1: agent-info-trusted ; agent-info-trusted
}

agent-info = {
  0: text ; display-name
  1: text ; model-name
  ? 2: bool ; audio-only
}

resolution = {
  0: uint ; horizontal-resolution
  1: uint ; vertical-resolution
  2: [1* float64] ; refresh-rates
}

<!-- TODO(jophba): what codecs do we support? -->
<!-- TODO(jophba): do we need this? -->
<!-- TODO(jophba): flag enum? -->
codec = (

)

streaming-capabilities = {
  0: [1* resolution] ; supported-resolutions
  ? 1: uint ; max-pixel-fill-rate
  ? 2: [1* codec] ; supported-codecs
}

; type key 12
agent-status-request = {
  request
  ? 1: status ; status
}

; type key 13
agent-status-response = {
  response
  ? 1: status ; status
}

status = {
}

request = (
 0: request-id ; request-id
)

response = (
 0: request-id ; request-id
)

request-id = uint

; type key 14
presentation-url-availability-request = {
  request
  1: [1* text] ; urls
  2: microseconds ; watch-duration
  3: int ; watch-id
}

; type key 15
presentation-url-availability-response = {
  response
  1: [1* url-availability] ; url-availabilities
}

; type key 103
presentation-url-availability-event = {
  1: int ; watch-id
  2: [1* url-availability] ; url-availabilities
}


; idea: use HTTP response codes?
url-availability = &(
  available: 0
  unavailable: 1
  invalid: 10
)

; type key 104
presentation-start-request = {
  request
  1: text ; presentation-id
  2: text ; url
  3: [* http-header] ; headers
}

http-header = [
  key: text
  value: text
]

; type key 105
presentation-start-response = {
  response
  1: &result ; result
  2: uint ; connection-id
}

; type key 106
presentation-termination-request = {
  request
  1: text ; presentation-id
  2: &(
    controller-called-terminate: 10
    user-terminated-via-controller: 11
    unknown: 255
  ) ; reason
}

; type key 107
presentation-termination-response = {
  response
  1: result ; result
}

; type key 108
presentation-termination-event = {
  1: text ; presentation-id
  2: &(
    receiver-called-terminate: 1
    user-terminated-via-receiver: 2
    controller-called-terminate: 10
    user-terminated-via-controller: 11
    receiver-replaced-presentation: 20
    receiver-idle-too-long: 30
    receiver-attempted-to-navigate: 31
    receiver-powering-down: 100
    receiver-crashed: 101
    unknown: 255
  ) ; reason
}

; type key 109
presentation-connection-open-request = {
  request
  1: text ; presentation-id
  2: text ; url
}

; type key 110
presentation-connection-open-response = {
  response
  1: &result ; result
  2: uint; connection-id
}

; type key 111
presentation-connection-close-request = {
  request
  1: uint ; connection-id
}

; type key 112
presentation-connection-close-response = {
  response
  1: &result ; result
}

; type key 113
presentation-connection-close-event = {
  1: uint; connection-id
  2: &(
    close-method-called: 1
    connection-object-discarded: 10
    unrecoverable-error-while-sending-or-receiving-message: 100
  ) ; reason
  ? 3: text ; error-message
}


; type key 16
presentation-connection-message = {
  1: uint ; connection-id
  2: bytes / text ; message
}

result = (
  success: 1
  invalid-url: 10
  invalid-presentation-id: 11
  timeout: 100
  transient-error: 101
  permanent-error: 102
  terminating: 103
  unknown-error: 199
)

; type key 17
remote-playback-availability-request = {
  request
  1: [* text] ; urls
  2: microseconds ; watch-duration
  3: int ; watch-id
}

; type key 18
remote-playback-availability-response = {
  response
  url-availabilities: [* url-availability]
}

; type key 114
remote-playback-availability-event = {
  1: int ; watch-id
  2: [* url-availability] ; url-availabilities
}

; type key 115
remote-playback-start-request = {
  request
  1: remote-playback-id ; remote-playback-id
  2: [* text] ; urls
  ? 3: [* text] ; text-track-urls
  ? 4: [* http-header] ; headers
  ? 5: remote-playback-controls ; controls
}

; type key 116
remote-playback-start-response = {
  response
  1: &result ; result
  ? 2: remote-playback-state ; state
}

; type key 117
remote-playback-termination-request = {
  request
  1: remote-playback-id ; remote-playback-id
  2: &(
    user-terminated-via-controller: 11
    unknown: 255
  ) ; reason
}

; type key 118
remote-playback-termination-response = {
  response
  1: &result ; result
}

; type key 119
remote-playback-termination-event = {
 1: remote-playback-id ; remote-playback-id
 2: &(
    receiver-called-terminate: 1
    user-terminated-via-receiver: 2
    receiver-idle-too-long: 30
    receiver-powering-down: 100
    receiver-crashed: 101
    unknown: 255
  ) ; reason
}

; type key 19
remote-playback-modify-request = {
  request
  1: remote-playback-id ; remote-playback-id
  2: remote-playback-controls ; controls
)

; type key 20
remote-playback-modify-response = {
  response
  1: &result ; result
  ? 2: remote-playback-state ; state
}

; type key 21
remote-playback-state-event = {
  1: remote-playback-id ; remote-playback-id
  2: remote-playback-state ; state
}

remote-playback-id = uint

remote-playback-controls = {
  ? 1: url ; source
  ? 2: &(none, metadata, auto) ; preload
  ? 3: bool ; loop
  ? 4: bool ; paused
  ? 5: bool ; muted
  ? 6: float ; volume
  ? 7: media-time ; seek
  ? 8: media-time ; fast-seek
  ? 9: float ; playback-rate
  ? 10: url ; poster
  ? 11: [* text] ; enabled-audio-track-ids
  ? 12: text ; selected-video-track-id
  ? 13: [* added-text-track] ; added-text-tracks
  ? 14: [* changed-text-track] ; changed-text-tracks
}

remote-playback-state = {
  ? 1: (rate: bool, preload: bool, poster: bool, added-text-track: bool, added-cues: bool) ; supports

  ? 2: url ; source
  ? 3: &(
    empty: 0
    idle: 1
    loading: 2
    no-source: 3
  ) ; loading
  ? 4: &(
    nothing: 0
    metdata: 1
    current: 2
    future: 3
    enough: 4
  ) ; loaded
  ? 5: media-error : error

  ? 6: media-time / unknown; epoch
  ? 7: media-time / unknown / forever ; duration
  ? 8: [* media-time-range] ; buffered-time-ranges
  ? 9: [* media-time-range] ; seekable-time-ranges
  ? 10: [* media-time-range] ; played-time-ranges

  ? 11: media-time ; position
  ? 12: float : playbackRate
  ? 13: bool ; paused
  ? 14: bool ; seeking
  ? 15: bool ; stalled
  ? 16: bool ; ended

  ? 17: float ; volume
  ? 18: bool ; muted

  ? 19: video-resolution / unknown ; resolution

  ? 20: [* audio-track-state] audio-tracks
  ? 21: [* video-track-state] video-tracks
  ? 22: [* text-track-state] text-tracks
}

added-text-track = {
  1: &(
    subtitles
    captions
    descriptions
    chapters
    metadata
  ) ; kind
  ? 2: text ; label
  ? 3: text ; language
}

changed-text-track = {
  1: text ; id
  2: mode ; mode
  ? 3: [* text-track-cue] ; added-cues
  ? 4: [* text] ; removed-cue-ids
}

text-track-mode = &(
  disabled
  showing
  hidden
)

text-track-cue = {
  1: text ; id
  2: media-time-range ; range
  3: text ; text
}

media-time-range = [
  start: media-time,
  end: media-time
]

media-time = [
  value: uint
  scale: uint
]

unknown = 0
forever = 1

media-error = [
  code: &(
    user-aborted: 1
    network-error: 2
    decode-error: 3
    source-not-supported: 4
  )
  message: text
]

track-state = (
  1: text ; id
  2: text ; label
  3: text ; language
)

audio-track-state = {
  track-state
  4: bool ; enabled
}

video-track-state = {
  track-state
  5 : bool ; selected
}

track-track-state = {
  track-state
  6 : mode ; text-track-mode
}


</pre>
